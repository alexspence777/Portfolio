{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda019cf-1edf-4ea2-87cd-c450d1ec97da",
   "metadata": {},
   "source": [
    "# Alex Spence\n",
    "DSC 630 Project Milestone 4 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d710d468-8982-439c-b9e4-777d4401bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values:\n",
      "LoanID            0\n",
      "Age               0\n",
      "Income            0\n",
      "LoanAmount        0\n",
      "CreditScore       0\n",
      "MonthsEmployed    0\n",
      "NumCreditLines    0\n",
      "InterestRate      0\n",
      "LoanTerm          0\n",
      "DTIRatio          0\n",
      "Education         0\n",
      "EmploymentType    0\n",
      "MaritalStatus     0\n",
      "HasMortgage       0\n",
      "HasDependents     0\n",
      "LoanPurpose       0\n",
      "HasCoSigner       0\n",
      "Default           0\n",
      "dtype: int64\n",
      "After SMOTE, training set class distribution: [180524 180524]\n",
      "Selected features: ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'InterestRate', 'EmploymentType_Part-time', 'EmploymentType_Unemployed', 'HasDependents_Yes', 'HasCoSigner_Yes']\n",
      "\n",
      "Logistic Regression Results (Threshold=0.4):\n",
      "AUC-ROC: 0.75\n",
      "Precision: 0.18\n",
      "Recall: 0.80\n",
      "F1-Score: 0.30\n",
      "\n",
      "Random Forest Results (Threshold=0.4):\n",
      "AUC-ROC: 0.73\n",
      "Precision: 0.19\n",
      "Recall: 0.75\n",
      "F1-Score: 0.30\n",
      "Best XGBoost params: {'learning_rate': 0.05, 'max_depth': 6, 'scale_pos_weight': 5}\n",
      "\n",
      "XGBoost Results (Threshold=0.35):\n",
      "AUC-ROC: 0.73\n",
      "Precision: 0.13\n",
      "Recall: 0.98\n",
      "F1-Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('loan_default.csv')\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "print(\"Checking for missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Remove outliers \n",
    "num_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
    "for col in num_cols:\n",
    "    cap = data[col].quantile(0.99)\n",
    "    data[col] = data[col].clip(upper=cap)\n",
    "\n",
    "cat_cols = ['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
    "data = data.drop('LoanID', axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('Default', axis=1)\n",
    "y = data['Default']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(k_neighbors=3, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE, training set class distribution:\", np.bincount(y_train_smote))\n",
    "\n",
    "# Feature selection with RFE\n",
    "lr = LogisticRegression(random_state=42)\n",
    "rfe = RFE(lr, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train_smote, y_train_smote)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "selected_features = X.columns[rfe.support_].tolist()\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Step 2: Visualizations\n",
    "# Sample data for scatterplot\n",
    "sample_data = data.sample(1000, random_state=42)\n",
    "\n",
    "# Histogram of default rate by credit score\n",
    "data['CreditScore_bin'] = pd.cut(data['CreditScore'], bins=[0, 600, 700, 1000], labels=['<600', '600-700', '>700'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='CreditScore_bin', y='Default', data=data, estimator=np.mean)\n",
    "plt.title('Default Rate by Credit Score')\n",
    "plt.ylabel('Default Rate')\n",
    "plt.savefig('credit_score_default.png')\n",
    "plt.close()\n",
    "\n",
    "# Scatterplot: income vs. loan amount\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Income', y='LoanAmount', hue='Default', data=sample_data, alpha=0.5)\n",
    "plt.title('Income vs. Loan Amount by Default Status')\n",
    "plt.savefig('income_loan_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data[num_cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Build and Evaluate Models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, name, threshold=0.4):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} Results (Threshold={threshold}):\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f'{name}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return auc, precision, recall, f1\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(C=0.1, random_state=42)\n",
    "lr_scores = evaluate_model(lr, X_train_rfe, y_train_smote, X_test_rfe, y_test, \"Logistic Regression\", threshold=0.4)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=100, random_state=42)\n",
    "rf_scores = evaluate_model(rf, X_train_rfe, y_train_smote, X_test_rfe, y_test, \"Random Forest\", threshold=0.4)\n",
    "\n",
    "# XGBoost with cost-sensitive learning\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'scale_pos_weight': [3, 4, 5]\n",
    "}\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(xgb, xgb_params, cv=5, scoring='recall', n_jobs=-1)\n",
    "grid_search.fit(X_train_rfe, y_train_smote)\n",
    "xgb_best = grid_search.best_estimator_\n",
    "print(\"Best XGBoost params:\", grid_search.best_params_)\n",
    "\n",
    "# Apply sample weights for cost-sensitive learning\n",
    "sample_weights = np.where(y_train_smote == 1, 5, 1)  # Higher weight for defaults\n",
    "xgb_best.fit(X_train_rfe, y_train_smote, sample_weight=sample_weights)\n",
    "xgb_scores = evaluate_model(xgb_best, X_train_rfe, y_train_smote, X_test_rfe, y_test, \"XGBoost\", threshold=0.35)\n",
    "\n",
    "# Feature importance plot for XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': xgb_best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.savefig('xgboost_feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'AUC-ROC': [lr_scores[0], rf_scores[0], xgb_scores[0]],\n",
    "    'Precision': [lr_scores[1], rf_scores[1], xgb_scores[1]],\n",
    "    'Recall': [lr_scores[2], rf_scores[2], xgb_scores[2]],\n",
    "    'F1-Score': [lr_scores[3], rf_scores[3], xgb_scores[3]]\n",
    "})\n",
    "results.to_csv('model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7fbe2-990e-436d-8426-c7efe05ce886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
